# Specification Driven Development (SDD) Workflow Guide

**Version**: 1.0
**Last Updated**: [Auto-generated by Steering Agent]

---

## Overview

This guide defines the standard workflow for Specification Driven Development using Musuhi agents. It ensures consistent, traceable development from requirements to deployment.

### SDD Principles

1. **Specification First** - Write detailed specifications before code
2. **Traceability** - Every code change links back to requirements
3. **Test-Driven** - Tests are derived from EARS requirements
4. **Documentation-Centric** - Documentation drives development

---

## Workflow Stages

```mermaid
graph LR
    A[Spike] -->|Optional| B[Requirements]
    B --> C[Design]
    C --> D[Tasks]
    D --> E[Implementation]
    E --> F[Review]
    F --> G[Testing]
    G --> H[Deployment]
    H --> I[Monitoring]
    I --> J[Retrospective]
    J -.->|Next Iteration| B
```

---

## Stage 0: Spike / PoC (Optional)

**When to use**: æŠ€è¡“çš„ãªä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„å ´åˆã€æ–°æŠ€è¡“ã®è©•ä¾¡ãŒå¿…è¦ãªå ´åˆ

**Agent**: `@software-developer`, `@system-architect`

**Output**: 
- `spike-{topic}.md` - èª¿æŸ»çµæœã¨çµè«–
- PoC ã‚³ãƒ¼ãƒ‰ï¼ˆä½¿ã„æ¨ã¦å¯ï¼‰

**Purpose**:
- æŠ€è¡“çš„å®Ÿç¾å¯èƒ½æ€§ã®æ¤œè¨¼
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§ã®ç¢ºèª
- ãƒ©ã‚¤ãƒ–ãƒ©ãƒª/ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®è©•ä¾¡
- ãƒªã‚¹ã‚¯ã®æ—©æœŸç™ºè¦‹

**Timeboxing**: æœ€å¤§ 1-2 æ—¥ï¼ˆè¶…ãˆã‚‹å ´åˆã¯åˆ†å‰²ï¼‰

**Completion Criteria**:
- [ ] æŠ€è¡“çš„ãªè³ªå•ã«å›ç­”ã§ããŸ
- [ ] Go/No-Go ã®åˆ¤æ–­ãŒã§ããŸ
- [ ] ãƒªã‚¹ã‚¯ã¨åˆ¶ç´„ãŒæ˜ç¢ºã«ãªã£ãŸ
- [ ] æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒæ±ºã¾ã£ãŸ

**Output Format**:
```markdown
# Spike: [Topic]

## Question
ä½•ã‚’æ¤œè¨¼ã™ã‚‹ã®ã‹ï¼Ÿ

## Approach
ã©ã®ã‚ˆã†ã«æ¤œè¨¼ã—ãŸã‹ï¼Ÿ

## Findings
ä½•ãŒã‚ã‹ã£ãŸã‹ï¼Ÿ

## Recommendation
æ¨å¥¨äº‹é …ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

## Time Spent
å®Ÿéš›ã«ã‹ã‹ã£ãŸæ™‚é–“
```

**Next Stage**: Requirements Definition

---

## Stage 1: Research (Optional)

**When to use**: When technical decisions need investigation

**Agent**: No specific agent (manual research or general exploration)

**Output**: `research.md` (Template: `steering/templates/research.md`)

**Purpose**:
- Evaluate technology options
- Benchmark performance
- Compare alternatives
- Validate technical feasibility

**Completion Criteria**:
- [ ] Research questions answered
- [ ] Options analyzed with pros/cons
- [ ] Recommendation made
- [ ] Risks identified

**Next Stage**: Requirements Definition

---

## Stage 2: Requirements Definition

**Agent**: `@requirements-analyst`

**Input**:
- Steering context (`steering/structure.md`, `steering/tech.md`, `steering/product.md`)
- Research document (if exists)
- Stakeholder input

**Output**:
- `requirements.md` using EARS format (Template: `steering/templates/requirements.md`)
- Functional requirements
- Non-functional requirements
- User stories

**Purpose**:
- Define **WHAT** the system must do
- Establish testable acceptance criteria
- Prioritize features (MoSCoW method)
- Create traceability matrix

**Completion Criteria**:
- [ ] All requirements written in EARS format
- [ ] Requirements are testable and verifiable
- [ ] Each requirement has unique ID
- [ ] Priority assigned to each requirement
- [ ] Stakeholder review completed

**EARS Format Requirements**:
- Use WHEN, WHILE, IF...THEN, WHERE, SHALL patterns
- See `steering/rules/ears-format.md` for guidelines
- Every acceptance criterion must be testable

**Next Stage**: Technical Design

---

## Stage 3: Technical Design

**Agent**: `@system-architect`

**Input**:
- Requirements document with EARS criteria
- Steering context (`steering/structure.md`, `steering/tech.md`)
- Research document (if exists)

**Output**:
- `design.md` (Template: `steering/templates/design.md`)
- Architecture diagrams (C4 Model, sequence diagrams)
- Component specifications
- API design
- Database schema

**Purpose**:
- Define **HOW** the system will be built
- Map EARS requirements to design components
- Establish architecture patterns
- Identify technical dependencies

**Completion Criteria**:
- [ ] Architecture pattern selected and justified
- [ ] All EARS requirements mapped to components
- [ ] Sequence diagrams for major flows
- [ ] Technology stack aligned with `steering/tech.md`
- [ ] Security and performance designs included
- [ ] Technical review completed

**Design-to-Requirements Mapping**:
- Each component must reference requirements it implements
- EARS patterns guide component behavior design
- Error handling design matches IF...THEN requirements

**Next Stage**: Implementation Planning

---

## Stage 4: Implementation Planning

**Agent**: `@project-manager` or `@software-developer`

**Input**:
- Requirements document
- Design document
- Steering context

**Output**:
- `tasks.md` (Template: `steering/templates/tasks.md`)
- Task breakdown with priorities
- Timeline and resource allocation
- Requirements coverage matrix

**Purpose**:
- Break design into actionable tasks
- Ensure every requirement has implementing tasks
- Establish dependencies and critical path
- Assign ownership and estimate effort

**Completion Criteria**:
- [ ] All requirements have implementing tasks
- [ ] Tasks have clear acceptance criteria
- [ ] Dependencies identified
- [ ] Timeline estimated
- [ ] Team assignments made
- [ ] 100% requirements coverage

**Task-to-Requirements Traceability**:
- Every task references specific requirement IDs
- EARS acceptance criteria become task completion criteria
- Requirements coverage matrix shows no gaps

**Next Stage**: Implementation

---

## Stage 5: Implementation

**Agent**: `@software-developer`

**Input**:
- Tasks document
- Design document
- Steering context (`steering/structure.md`, `steering/tech.md`)

**Output**:
- Source code
- Unit tests
- Code documentation

**Purpose**:
- Implement design according to tasks
- Write code that satisfies EARS requirements
- Create unit tests for each requirement

**Completion Criteria**:
- [ ] All tasks marked as complete
- [ ] Code follows `steering/structure.md` patterns
- [ ] Uses technologies from `steering/tech.md`
- [ ] Unit test coverage â‰¥ 80%
- [ ] Code review approved
- [ ] No critical bugs

**Implementation Guidelines**:
- Reference requirement IDs in code comments
- Each EARS requirement maps to specific code/tests
- Follow SOLID principles
- Use design patterns from `steering/structure.md`

**Next Stage**: Code Review

---

## Stage 5.5: Code Review

**Agent**: `@code-reviewer`, `@security-auditor`

**Input**:
- Implementation code
- Unit tests
- Design document
- Requirements document

**Output**:
- ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆ
- æ‰¿èª/ä¿®æ­£è¦æ±‚
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æŒ‡æ‘˜äº‹é …

**Purpose**:
- ã‚³ãƒ¼ãƒ‰å“è³ªã®ç¢ºä¿
- è¨­è¨ˆã¨ã®æ•´åˆæ€§ç¢ºèª
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã®æ¤œå‡º
- çŸ¥è­˜å…±æœ‰ã¨ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°

**Review Checklist**:
- [ ] ã‚³ãƒ¼ãƒ‰ãŒè¨­è¨ˆã«æº–æ‹ ã—ã¦ã„ã‚‹
- [ ] SOLID åŸå‰‡ã«å¾“ã£ã¦ã„ã‚‹
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒé©åˆ‡
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹
- [ ] ãƒ†ã‚¹ãƒˆãŒååˆ†
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒæ›´æ–°ã•ã‚Œã¦ã„ã‚‹
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡ŒãŒãªã„

**MCP Tools** (CodeGraph åˆ©ç”¨æ™‚):
- `find_callers` - å¤‰æ›´ã®å½±éŸ¿ç¯„å›²ç¢ºèª
- `find_dependencies` - ä¾å­˜é–¢ä¿‚ã®ç¢ºèª
- `query_codebase` - é¡ä¼¼ã‚³ãƒ¼ãƒ‰ã®æ¤œç´¢

**Review Types**:

| ã‚¿ã‚¤ãƒ— | ç›®çš„ | æ™‚é–“ç›®å®‰ |
|--------|------|---------|
| **Quick Review** | å°ã•ãªå¤‰æ›´ã€ãƒã‚°ä¿®æ­£ | 15-30åˆ† |
| **Standard Review** | æ©Ÿèƒ½è¿½åŠ  | 1-2æ™‚é–“ |
| **Deep Review** | ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¤‰æ›´ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ | åŠæ—¥ |

**Next Stage**: Testing

---

## Stage 6: Testing

**Agent**: `@test-engineer`

**Input**:
- Requirements document (EARS format)
- Design document
- Implementation code
- Tasks document

**Output**:
- Test plans
- Test cases (unit, integration, E2E)
- Test results and coverage reports

**Purpose**:
- Verify all EARS requirements are met
- Convert EARS criteria to automated tests
- Achieve comprehensive test coverage

**Completion Criteria**:
- [ ] All EARS requirements have test cases
- [ ] Unit tests: 80%+ coverage
- [ ] Integration tests: All API endpoints
- [ ] E2E tests: All user flows
- [ ] All tests passing
- [ ] Performance tests meet NFRs

**EARS-to-Test Mapping**:
- `WHEN [event], System SHALL [action]` â†’ Given-When-Then test
- `IF [error], THEN System SHALL [response]` â†’ Error handling test
- `The System SHALL [always]` â†’ Invariant test

**Next Stage**: Deployment

---

## Stage 7: Deployment

**Agent**: `@devops-engineer`

**Input**:
- Implementation code (all tests passing)
- Design document (deployment strategy)
- Steering context

**Output**:
- Deployed application
- CI/CD pipeline configuration
- Deployment documentation

**Purpose**:
- Deploy to staging/production
- Set up monitoring and alerting
- Establish rollback procedures

**Completion Criteria**:
- [ ] Deployed to staging
- [ ] Smoke tests passed
- [ ] Deployed to production
- [ ] Health checks passing
- [ ] Monitoring configured
- [ ] Rollback plan tested

**Next Stage**: Monitoring & Maintenance

---

## Stage 8: Monitoring & Maintenance

**Agents**: `@devops-engineer`, `@performance-optimizer`, `@security-auditor`

**Input**:
- Deployed application
- Requirements (NFRs)
- Design document

**Output**:
- Monitoring dashboards
- Incident reports
- Performance reports
- Security audit reports

**Purpose**:
- Ensure system meets NFRs in production
- Detect and respond to issues
- Continuous improvement

**Completion Criteria**:
- [ ] Metrics collected and visualized
- [ ] Alerts configured
- [ ] NFRs being met (response time, uptime, etc.)
- [ ] Security vulnerabilities addressed
- [ ] Performance optimized

**Next Stage**: Retrospective

---

## Stage 9: Retrospective

**Agent**: `@project-manager`, `@orchestrator`

**When to run**: 
- å„ã‚¹ãƒ—ãƒªãƒ³ãƒˆ/ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚
- æ©Ÿèƒ½ãƒªãƒªãƒ¼ã‚¹å¾Œ
- é‡å¤§ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¾Œ

**Input**:
- å®Œäº†ã—ãŸè¦ä»¶/ã‚¿ã‚¹ã‚¯
- ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ¬ãƒãƒ¼ãƒˆ
- ãƒãƒ¼ãƒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹

**Output**:
- `steering/memories/lessons_learned.md` ã¸ã®è¿½è¨˜
- æ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ 
- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ”¹å–„ææ¡ˆ

**Purpose**:
- ãƒ—ãƒ­ã‚»ã‚¹ã®ç¶™ç¶šçš„æ”¹å–„
- çŸ¥è­˜ã®è“„ç©ã¨å…±æœ‰
- ãƒãƒ¼ãƒ ã®æˆé•·

**Retrospective Format**:

```markdown
## [YYYY-MM-DD] Sprint/Release X.X æŒ¯ã‚Šè¿”ã‚Š

### ğŸ“Š Metrics
- è¦ä»¶æ•°: X
- ã‚¿ã‚¹ã‚¯å®Œäº†ç‡: X%
- ãƒã‚°ç™ºè¦‹ï¼ˆãƒ†ã‚¹ãƒˆæ™‚/æœ¬ç•ªï¼‰: X/X
- æ‰‹æˆ»ã‚Šå›æ•°: X
- ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ : X æ—¥

### ğŸ‘ What Went Well
- [è‰¯ã‹ã£ãŸç‚¹]

### ğŸ”§ What Could Be Improved
- [æ”¹å–„ç‚¹]

### ğŸ’¡ Insights
- [æ°—ã¥ãã€å­¦ã³]

### ğŸ“‹ Action Items
- [ ] [å…·ä½“çš„ãªæ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³]
- [ ] [æ‹…å½“è€…: XXXã€æœŸé™: YYYY-MM-DD]
```

**Discussion Questions**:
1. ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã©ã“ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã ã£ãŸã‹ï¼Ÿ
2. ã©ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§æ‰‹æˆ»ã‚ŠãŒç™ºç”Ÿã—ãŸã‹ï¼Ÿ
3. äº‹å‰ã«é˜²ã’ãŸå•é¡Œã¯ã‚ã£ãŸã‹ï¼Ÿ
4. æ¬¡å›æ”¹å–„ã§ãã‚‹ã“ã¨ã¯ä½•ã‹ï¼Ÿ

**Next Stage**: æ¬¡ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã® Requirements ã¸

---

## Document Lifecycle

### Document Status Progression

```
Draft â†’ In Review â†’ Approved â†’ Implemented â†’ Deprecated
```

### Version Control

- All documents must be version controlled (git)
- Use semantic versioning (v1.0, v1.1, v2.0)
- Track changes in document control section
- Link related documents (requirements â†’ design â†’ tasks)

### Document Updates

**When to update**:
- Requirements change â†’ Update all dependent documents
- Design changes â†’ Update design.md and tasks.md
- Implementation deviates â†’ Update design or create ADR

**Update Process**:
1. Identify impacted documents
2. Update primary document
3. Propagate changes to dependent documents
4. Update traceability matrices
5. Get stakeholder approval
6. Commit changes with descriptive message

---

## Traceability Matrix

Maintain bidirectional traceability:

```
Requirement â†â†’ Design Component â†â†’ Task â†â†’ Code â†â†’ Test
```

**Example**:
- `REQ-001`: WHEN user clicks submit, System SHALL validate
  - **Design**: `FormValidator` component (design.md section 4.2)
  - **Task**: Task 2.3 "Implement form validation"
  - **Code**: `src/validators/FormValidator.ts:25`
  - **Test**: `tests/FormValidator.test.ts:test_submit_validation()`

---

## Agent Handoffs

### Requirements â†’ Design

**Handoff Artifacts**:
- `requirements.md` with EARS acceptance criteria
- Requirements prioritization (MoSCoW)

**Design Agent Responsibilities**:
- Map each EARS requirement to design components
- Validate technical feasibility
- Create architecture that supports all requirements

---

### Design â†’ Implementation

**Handoff Artifacts**:
- `design.md` with component specifications
- `tasks.md` with implementation plan

**Developer Responsibilities**:
- Implement according to design
- Reference requirement IDs in code
- Write unit tests for each requirement

---

### Implementation â†’ Testing

**Handoff Artifacts**:
- Source code with unit tests
- Requirements document (EARS format)

**Test Engineer Responsibilities**:
- Convert EARS criteria to test cases
- Verify all requirements are tested
- Report any requirement gaps

---

## Quality Gates

### Requirements Phase Gate

- [ ] All requirements in EARS format
- [ ] Each requirement testable
- [ ] Requirements approved by stakeholders
- [ ] Traceability matrix created

**Gate Keeper**: Product Manager / System Architect

---

### Design Phase Gate

- [ ] All requirements mapped to design
- [ ] Architecture aligned with `steering/structure.md`
- [ ] Tech stack matches `steering/tech.md`
- [ ] Security and performance considered
- [ ] Design reviewed and approved

**Gate Keeper**: System Architect / Tech Lead

---

### Implementation Phase Gate

- [ ] All tasks completed
- [ ] Code review approved
- [ ] Unit tests â‰¥ 80% coverage
- [ ] No critical bugs
- [ ] Documentation updated

**Gate Keeper**: Tech Lead

---

### Testing Phase Gate

- [ ] All EARS requirements tested
- [ ] All tests passing
- [ ] Performance tests meet NFRs
- [ ] Security tests passed

**Gate Keeper**: QA Lead

---

### Deployment Phase Gate

- [ ] Staging deployment successful
- [ ] Smoke tests passed
- [ ] Production deployment successful
- [ ] Monitoring configured
- [ ] Rollback tested

**Gate Keeper**: DevOps Lead

---

## Best Practices

### DO:
- âœ… Always start with requirements (EARS format)
- âœ… Reference `steering/` context in every stage
- âœ… Maintain traceability from requirements to code
- âœ… Write tests based on EARS acceptance criteria
- âœ… Update documents when changes occur
- âœ… Use templates from `steering/templates/`

### DON'T:
- âŒ Skip requirements documentation
- âŒ Write code before design
- âŒ Ignore EARS format guidelines
- âŒ Break traceability links
- âŒ Deploy without testing
- âŒ Forget to update steering context

---

## Document Templates

| Template | Location | Purpose |
|----------|----------|---------|
| Requirements | `steering/templates/requirements.md` | EARS-format requirements with acceptance criteria |
| Design | `steering/templates/design.md` | Technical architecture and component design |
| Tasks | `steering/templates/tasks.md` | Implementation plan with task breakdown |
| Research | `steering/templates/research.md` | Technical research and options analysis |

---

## References

- **EARS Format**: `steering/rules/ears-format.md` - Requirements writing standard
- **Architecture Patterns**: `steering/structure.md` - Project architecture guidelines
- **Technology Stack**: `steering/tech.md` - Approved technologies
- **Product Context**: `steering/product.md` - Business goals and user context

---

## Workflow Customization

This is the standard workflow. Projects may customize based on:
- **Project Size**: Smaller projects may combine stages
- **Team Size**: Larger teams may add more review gates
- **Methodology**: Agile teams may iterate through stages in sprints
- **Domain**: Some domains require additional stages (regulatory approval, etc.)

**When customizing**:
1. Document deviations in `steering/structure.md`
2. Maintain core SDD principles (specification-first, traceability)
3. Keep EARS format for requirements
4. Ensure all stages have clear quality gates

---

**Remember**: Good specifications save time in development and testing. Follow this workflow to ensure quality, traceability, and successful delivery.
